Only in homework1/q2.c.diff: __pycache__
diff -u 01-svhn/common.py homework1/q2.c.diff/common.py
--- 01-svhn/common.py	2019-03-20 18:44:19.983937800 +0800
+++ homework1/q2.c.diff/common.py	2019-03-20 19:19:58.383000000 +0800
@@ -12,7 +12,7 @@
 
 class Config:
     '''where to write all the logging information during training(includes saved models)'''
-    log_dir = '../train_log'
+    log_dir = '../../train_log'
 
     '''where to write model snapshots to'''
     log_model_dir = os.path.join(log_dir, 'models')
@@ -23,7 +23,7 @@
     nr_channel = 3
     image_shape = (32, 32)
     nr_class = 10
-    nr_epoch = 60
+    nr_epoch = 40
     weight_decay = 1e-10
 
     show_interval = 100
diff -u 01-svhn/dataset.py homework1/q2.c.diff/dataset.py
--- 01-svhn/dataset.py	2019-03-20 18:59:34.214717600 +0800
+++ homework1/q2.c.diff/dataset.py	2019-03-18 18:46:57.725890400 +0800
@@ -15,10 +15,9 @@
 
 from common import config
 
-class Dataset():
-    #dataset_path = '../../dataset/SVHN'
-    dataset_path = '..'
 
+class Dataset():
+    dataset_path = '../..'
 
     def __init__(self, dataset_name):
         self.minibatch_size = config.minibatch_size
@@ -44,13 +43,44 @@
         datas = np.concatenate(datas_list, axis=3)
         labels = np.concatenate(labels_list, axis=0)
         if self.ds_name == "train":
-            self.instances=10000
+            datas, labels = self.shuffle_data(datas, labels)
+            self.index = 0
+            List = [1, 2, 3, 4, 5]
+            self.count = [0 for i in range(len(List))]
+            datas, labels = self.reduce_size(datas, labels, List, 6000)
+            self.instances=self.index
         self.samples_mat = {
             'X': datas,
             'Y': labels,
         }
         return self
 
+    def shuffle_data(self, data, label):
+        index = np.arange(self.instances)
+        np.random.shuffle(index)
+        data = data[:, :, :, index]  # X_train是训练集，y_train是训练标签
+        label = label[index]
+        return data, label
+
+    def reduce_size(self, data, labels, List, num):
+        for j in range(data.shape[3]):
+            if labels[j, :][0] == 10:
+                labels[j, :][0] = 0
+            if labels[j, :][0] in List:
+                for i in range(len(List)):
+                    if labels[j, :][0] == List[i] and self.count[i] < num:
+                        self.count[i] += 1
+                        data[:, :, :, self.index] = data[:, :, :, j]
+                        labels[self.index, :] = labels[j, :][0]
+                        self.index += 1
+                        break
+            else:
+                data[:, :, :, self.index] = data[:, :, :, j]
+                labels[self.index, :] = labels[j, :]
+                self.index += 1
+        print(data[:, :, :, :self.index].shape, labels[:self.index, :].shape)
+        return data[:, :, :, :self.index], labels[:self.index, :]
+
     @property
     def instances_per_epoch(self):
         return self.instances
@@ -68,7 +98,6 @@
             img = cv2.resize(img, config.image_shape)
             yield img.astype(np.float32), np.array(label, dtype=np.int32)
 
-
 if __name__ == "__main__":
     ds = Dataset('train')
     ds = ds.load()
@@ -83,10 +112,9 @@
             imggrid.append(img)
 
         imggrid = np.array(imggrid).reshape((5, 5, img.shape[0], img.shape[1], img.shape[2]))
-        imggrid = imggrid.transpose((0, 2, 1, 3, 4)).reshape((5*img.shape[0], 5*img.shape[1], 3))
+        imggrid = imggrid.transpose((0, 2, 1, 3, 4)).reshape((5 * img.shape[0], 5 * img.shape[1], 3))
         cv2.imshow('', imggrid.astype('uint8'))
         c = chr(cv2.waitKey(0) & 0xff)
         if c == 'q':
             exit()
         imggrid = []
-
diff -u 01-svhn/train.py homework1/q2.c.diff/train.py
--- 01-svhn/train.py	2019-03-19 13:01:10.000000000 +0800
+++ homework1/q2.c.diff/train.py	2019-03-20 19:07:05.045000000 +0800
@@ -71,7 +71,7 @@
 
     ## train config
     global_steps = tf.Variable(0, trainable=False)
-    boundaries = [train_set.minibatchs_per_epoch*15, train_set.minibatchs_per_epoch*40]
+    boundaries = [train_set.minibatchs_per_epoch*15, train_set.minibatchs_per_epoch*25]
     values = [0.01, 0.001, 0.0005]
     lr = tf.train.piecewise_constant(global_steps, boundaries, values)
     #opt = tf.train.MomentumOptimizer(lr, momentum=0.9) # set optimizer
